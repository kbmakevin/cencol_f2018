# Data Sets Repo:
https://archive.ics.uci.edu/ml/datasets.html

# Weka
https://www.cs.waikato.ac.nz/ml/weka/
- simpler to use than TensorFlow and SciKit
	- need to know how to program to use these ones
	- weka can master in matter of hour or more

# dimension reduction
- Dimension Reduction refers to the process of converting a set of data having vast dimensions into data with lesser dimensions ensuring that it conveys similar information concisely. These techniques are typically used while solving machine learning problems to obtain better features for a classification or regression task.

# overfitting
-  overfitting is "the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit additional data or predict future observations reliably".
- make algorithm work with all existing data 100%
	- this could pose a problem, if any data falls outside of this super specific data set, algorithm will not work
- resolve this issue by splitting data into two parts
	- e.g. 100 pcs of data in data set
		- use 80 pcs to create algorithms
			- Training data
		- use remaining 20 pcs to test the algorithms to determine which one gives most accurate resutls
			- Testing data
# K nearest neighbours
- if equal distance b/t point on red and blue, use k # of nearest neighbours, closer to which group of neighbours to tie break 

# Neural Network - Deep Learning
https://www.youtube.com/watch?v=aircAruvnKk


